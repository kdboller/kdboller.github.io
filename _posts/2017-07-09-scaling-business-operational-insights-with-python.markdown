---
layout: post
title:  "Scaling Business and Operational Insights with Python"
date:   2017-07-09 12:00:00 -0500
categories: 
---

<!-- <img src="/assets/4_OKC_players_in_2011.jpg" alt="Kevin Durant with OKC Teammates" height="500"  style="width: 100%"> -->

<h1><strong>Please note that this post is still under development but a significant amount has now been completed.</strong></h1>

<p>
    In recent months, I’ve written about some of the critical undertakings and initiatives which I oversee as VP of Product at FloSports.  
  These have included my efforts to build a data informed culture through product experimentation, our overall approach to our analytics tech stack, 
  and our approach to building and reviewing our rolling financial forecasts.
</p>

<p>
    I’ve also mentioned that the implementation of our data warehouse and the use of data analytics software, including Periscope Data, Segment, 
  and Mode Analytics have been fairly transformative across the company.  And, as business intelligence and data analysis requests and 
  feedback grow within an organization, it is critical to put processes and analytical procedures in place that reduce the queuing of data requests
  -- fast-paced and efficient approaches significantly reduce the time gathering the data and increase the level of insight derived from the data.
</p>

<p><i>In other words, spend less time calculating your LTV and more time focusing on efforts to grow your LTV. </i></p>

<p>
<strong><u>What I will cover in the next two posts:</u></strong>
<ul>
  <li>Cohort retention analysis in Python; I discovered this over a year ago on Greg Reda’s blog, and it was remarkably helpful</li>
    <ul><li>Taking this an additional step further and calculating weighted average retention for monthly cohorts</li>
    <li>This can then become a single series fed directly into a financial model</li></ul>
  <li>The power of Mode Analytics, which combines SQL and Python into a single web application</li>
    <ul>
      <li>Outside of Mode, I use Jupyter Notebook for all analysis in Python</li>
      <li>Mode Analytics has a powerful offering for Python, which is completely self-contained within their overall reporting application</li>
    </ul> 
  <li>The use of Python, in place of Excel, to conduct large scale financial and operational analysis; the analysis / dataframes can ultimately, as the last step, be pasted into a financial model</li>
      <ul><li>The best resource I’ve found for Python business application to-date is Chris Moffit’s Practical Business Python blog</li>
          <li><u>Note that this will be part of a follow-up post.</u></li>
      </ul>
</ul>
</p>

<strong><u>Cohort Retention Analysis with Python</u></strong>
<p>
Rather than reconstruct Greg Reda’s remarkably helpful post, I will simply continue from where he leaves off by showing how to calculate
M1, M2, etc. weighted average retention.</p>

<p>
As mentioned in this guest post on Andrew Chen’s blog, Christoph Janz has written some of the most helpful posts on SaaS metrics and cohort analyses.
One of the screenshots in Christoph’s guest post, from his model, shows the calculated weighted average retention by cohort month.
</p>

<p>
Here’s a screenshot from that guest post of what this looks like:
<img src="/assets/ChristophJanz_CohortAnalysisNotes.png" alt="Janz Cohort Analyses Screenshot" height="500"  style="width: 100%">

</p>

<p>
I certainly believe Christoph's model and overall helpfulness to SaaS companies is fairly outstanding.  However, as a company scales, there are challenges with activities such as pasting cohort data into a model and then calculating weighted average retention, and other metrics, within Excel.
</p>
<p>
<strong>At FloSports, I am constantly thinking about and looking to create scaleable solutions to deal with some of the challenges which we've run into.</strong> Some examples of these include:
<ul>
    <li>We have 25+ verticals with multiple subscription offerings.</li>
    <li>New data is constantly being generated by subscribers, including experimentation data, and we need to be able to quickly evaluate all of this multiple ways in order to "cut our losers quickly and let our winners run."</li>
    <li>Our verticals are at different stages within their lifecycles, and building and updating flexible subscriber waterfalls in Excel, as one example, can be rather time consuming.</li>
</ul></p>

<strong><u>Calculating Weighted Average Subscriber Retention with Python</u></strong>
<p>
If you would like to follow along with this explanation in Jupyter notebook, you will just need to use Greg Reda’s code from his post, which I linked to, in order to
arrive at my starting point -- I’m starting after his last code snippet, which uses Seaborn and generates a heat map.
</p>

<p>
    In his post, Greg used unstack in order to create a matrix where each column is the Cohort Group and each row is the Cohort Period.
    
Using this unstack approach and then resetting the index, we have a flattened dataframe which we can now manipulate in order to calculate the weighted average retention by Cohort Period, e.g., Month 1.  Below the code block is what the output for this dataframe looks like in Jupyter Notebook.
</p>

```python
# Unstack the TotalUsers
unstacked = cohorts['TotalUsers'].unstack(0)
unstacked.reset_index()
```

<img src="/assets/unstacked_df.png" alt="Unstacked Cohorts Dataframe" height="400"  style="width: 100%">

<p>We have successfully manipulated our subscriber data in order to create Cohort Groups and Cohort Periods for those groups, in large part thanks to Greg; and now we can create a separate dataframe which will contain our weighted average retentions across these combined cohorts for each of their monthly period for which we have data.</p>

<p>Below, we essentially create a dataframe with the reset index, calculate the sums across all rows (which represent the Cohort Periods), calculate weighted percentages by dividing by the first row, and then transpose the weighted_average dataframe to become a three-row dataframe; this three-row dataframe has Total Users and the Percentage of Retained Users indexed by Cohort Period Month.</p>

```python
# Create a weighted data frame with a reset index
weighted = unstacked.reset_index()

# Drop the Cohort Period from the dataframe to calculate the sums
weighted = weighted.drop('CohortPeriod', 1)

# Sum the users across all of the rows
total_users = weighted.sum(axis=1)

# Calculate percents by dividing each row by the row at index 0
pcts = total_users / total_users[0]

# Calculate weighted averge by creating a dataframe using a sum + percents dictionary key:value pairing.
weighted_average = pd.DataFrame(dict(total_users = total_users, pcts = pcts)).reset_index()

# Drop the index column out of the weighted average dataframe
weighted_average = weighted_average.drop('index', 1)

# Transpose the weighted average dataframe
weighted_average_transpose = weighted_average.transpose()
```

<img src="/assets/weighted_average_transpose.png" alt="Unstacked Cohorts Dataframe" height="125"  style="width: 100%">

<p>As you can see from the data above, across all of the Cohorts we had 757 total users; in the month after their initial purchase, ~32% were retained in the second month -- at FloSports, we call this M1 retention since M0 is the initial payment month.
</p>

<p>In the financial models which I build and collaborate on, we build a retention curve schedule worksheet, which we flex by business case / vertical.  Hopefully I have made the time savings Python affords inn acquiring the data to be pasted into these curves to be rather compelling.  
</p>    

<p>
</p>

<strong><u>Mode Analytics and its Python Notebook</u></strong>

 


